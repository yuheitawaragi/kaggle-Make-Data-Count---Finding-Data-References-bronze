{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":82370,"databundleVersionId":13015230,"sourceType":"competition"},{"sourceId":248118764,"sourceType":"kernelVersion"},{"sourceId":166368,"sourceType":"modelInstanceVersion","modelInstanceId":141565,"modelId":164048}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":474.866415,"end_time":"2025-07-30T12:51:20.001095","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-07-30T12:43:25.13468","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! uv pip uninstall --system 'tensorflow'\n! uv pip install --system --no-index --find-links='/kaggle/input/latest-mdc-whls/whls' 'pymupdf' 'vllm' 'triton' 'logits-processor-zoo' 'numpy<2'\n! mkdir -p /tmp/src","metadata":{"_cell_guid":"eae4b221-a822-451f-8f4b-134c3f9bfe2c","_uuid":"b1883565-f717-4130-a662-5bb541f45ea1","collapsed":false,"execution":{"iopub.status.busy":"2025-08-01T03:49:06.376608Z","iopub.execute_input":"2025-08-01T03:49:06.376918Z","iopub.status.idle":"2025-08-01T03:49:29.373634Z","shell.execute_reply.started":"2025-08-01T03:49:06.376898Z","shell.execute_reply":"2025-08-01T03:49:29.372761Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":20.083729,"end_time":"2025-07-30T12:43:50.835737","exception":false,"start_time":"2025-07-30T12:43:30.752008","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /tmp/src/helpers.py\nimport logging, os, kagglehub, inspect\nfrom pathlib import Path\nimport polars as pl\n\nIS_KAGGLE_ENV = sum(['KAGGLE' in k for k in os.environ]) > 0\nIS_KAGGLE_SUBMISSION = bool(os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"))\nCOMP_DIR = Path(('/kaggle/input/make-data-count-finding-data-references' if IS_KAGGLE_SUBMISSION else kagglehub.competition_download('make-data-count-finding-data-references')))\nPDF_DIR = COMP_DIR / ('test' if IS_KAGGLE_SUBMISSION else 'train') / 'PDF'\nWORKING_DIR = Path(('/kaggle/working/' if IS_KAGGLE_ENV else '.working/'))\n\nDOI_LINK = 'https://doi.org/'\n\nDEFAULT_LOG_LEVEL = os.getenv(\"LOG_LEVEL\", \"DEBUG\").upper() if not IS_KAGGLE_SUBMISSION else \"WARNING\"\nLOG_FILE_PATH = os.getenv(\"LOG_FILE\", \"logs/project.log\")\nLOG_DIR = Path(LOG_FILE_PATH).parent\n\nLOG_DIR.mkdir(parents=True, exist_ok=True)\n\nLOG_FORMAT = \"%(levelname)s %(asctime)s  [%(filename)s:%(lineno)d - %(funcName)s()] %(message)s\"\nLOG_DATEFMT = \"%Y-%m-%d %H:%M:%S\"\n\ndef get_logger(name=None):\n    if name is None:\n        frame = inspect.currentframe()\n        if frame is None or frame.f_back is None:\n            name = \"__main__\"\n        else:\n            name = frame.f_back.f_globals.get(\"__name__\", \"__main__\")\n\n    logger = logging.getLogger(name)\n\n    if not logger.handlers:\n        logger.setLevel(DEFAULT_LOG_LEVEL)\n        formatter = logging.Formatter(fmt=LOG_FORMAT, datefmt=LOG_DATEFMT)\n        ch = logging.StreamHandler()\n        ch.setLevel(DEFAULT_LOG_LEVEL)\n        ch.setFormatter(formatter)\n        fh = logging.FileHandler(LOG_FILE_PATH)\n        fh.setLevel(DEFAULT_LOG_LEVEL)\n        fh.setFormatter(formatter)\n        logger.addHandler(ch)\n        logger.addHandler(fh)\n        logger.propagate = False\n    return logger\n\ndef is_doi_link(name: str) -> pl.Expr:\n    return pl.col(name).str.starts_with(DOI_LINK)\n\ndef string_normalization(name: str) -> pl.Expr:\n    return pl.col(name).str.normalize(\"NFKC\").str.replace_all(r\"[^\\p{Ascii}]\", '').str.replace_all(r\"https?://zenodo\\.org/record/(\\d+)\", r\" 10.5281/zenodo.$1 \")\n\ndef get_df(parse_dir: str):\n    records = []\n    txt_files = list(Path(parse_dir).glob('*.txt'))\n    for txt_file in txt_files:\n        id_ = txt_file.stem\n        with open(txt_file, 'r') as f:\n            text = f.read()\n        records.append({'article_id': id_, 'text': text})\n    return pl.DataFrame(records).with_columns(string_normalization('text').alias('text'))\n\ndef assume_type(df: pl.DataFrame) -> pl.DataFrame:\n    return (\n        df.with_columns(pl.when(is_doi_link('dataset_id').or_(pl.col('dataset_id').str.starts_with('SAMN'))).then(pl.lit('Primary')).otherwise(pl.lit('Secondary')).alias('type'))\n    )\n\ndef score(df, gt, on, tag='all'):\n    hits = gt.join(df, on=on)\n    tp = hits.height\n    fp = df.height - tp\n    fn = gt.height - tp\n    f1 = 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) != 0 else 0.0\n    return f\"{tag} - f1: {f1:.4f} [{tp}/{fp}/{fn}]\"\n\ndef evaluate(df, on=['article_id', 'dataset_id']):\n    gt = pl.read_csv(COMP_DIR/'train_labels.csv').filter(pl.col('type')!='Missing')\n    return (\n        score(df, gt, on),\n        score(df.filter(is_doi_link('dataset_id')), gt.filter(is_doi_link('dataset_id')), on, 'doi'),\n        score(df.filter(~is_doi_link('dataset_id')), gt.filter(~is_doi_link('dataset_id')), on, 'acc'),\n    )","metadata":{"_cell_guid":"34135540-31fa-4d24-8934-acb1e0711a4f","_uuid":"92f33014-02d3-41cb-b906-ffeb89a3f353","collapsed":false,"execution":{"iopub.status.busy":"2025-08-01T03:49:29.375316Z","iopub.execute_input":"2025-08-01T03:49:29.375596Z","iopub.status.idle":"2025-08-01T03:49:29.383472Z","shell.execute_reply.started":"2025-08-01T03:49:29.375571Z","shell.execute_reply":"2025-08-01T03:49:29.382574Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.018527,"end_time":"2025-07-30T12:43:50.864121","exception":false,"start_time":"2025-07-30T12:43:50.845594","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /tmp/src/parse.py\n\"\"\"\nparser.py\n=========\n• Detects competition-submission mode\n• Parses both PDF and XML into plain text\n• Cleans text with the same heuristics\n• Writes /kaggle/working/output_dir/<article_id>.txt\n\"\"\"\n\nfrom __future__ import annotations\nfrom pathlib import Path\nimport multiprocessing as mp\nimport os, re, unicodedata, fitz               # PyMuPDF\nfrom tqdm.auto import tqdm\nimport pymupdf\nimport os, re, pathlib\nimport polars as pl\nfrom lxml import etree\nimport pymupdf\nfrom typing import Tuple\n\n# ----------------------- Environment / paths ---------------------------------\nIS_KAGGLE_SUBMISSION = bool(os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"))\nSPLIT = \"test\" if IS_KAGGLE_SUBMISSION else \"train\"\n\nBASE = Path(\"/kaggle/input/make-data-count-finding-data-references\") / SPLIT\nPDF_DIR = BASE / \"PDF\"\nXML_DIR = BASE / \"XML\"\n\nOUT_DIR = Path(\"/tmp/train_parse\")\nOUT_DIR.mkdir(parents=True, exist_ok=True)\n\n# XML & PDF Parsing\n\ndef xml_kind(path: pathlib.Path) -> str:\n    head = path.open('rb').read(2048).decode('utf8', 'ignore')\n    if 'www.tei-c.org/ns' in head:\n        return 'tei'\n    if re.search(r'(NLM|TaxonX)//DTD', head):\n        return 'jats'\n    if 'www.wiley.com/namespaces' in head:\n        return 'wiley'\n    if 'BioC.dtd' in head:\n        return 'bioc'\n    return 'unknown'\n\ndef xml2text(path: pathlib.Path) -> str:\n    kind = xml_kind(path)\n    root = etree.parse(str(path)).getroot()\n    if kind in ('tei', 'bioc', 'unknown'):\n        txt = ' '.join(root.itertext())\n    elif kind == 'jats':\n        elems = root.xpath('//body//sec|//ref-list')\n        txt = ' '.join(' '.join(e.itertext()) for e in elems)\n    elif kind == 'wiley':\n        elems = root.xpath('//*[local-name()=\"body\"]|//*[local-name()=\"refList\"]')\n        txt = ' '.join(' '.join(e.itertext()) for e in elems)\n    else:\n        txt = ' '.join(root.itertext())\n    txt = re.sub(r'10\\.\\d{4,9}/\\s+', '10.', txt)\n    return txt\n\ndef pdf2text(path: pathlib.Path, out_dir: pathlib.Path) -> None:\n    doc = pymupdf.open(str(path))\n    out = out_dir / f\"{path.stem}.txt\"\n    with open(out, \"wb\") as f:\n        for page in doc:\n            f.write(page.get_text().encode(\"utf8\"))\n            f.write(b\"\\n\")\n\n# Parse All PDFs & XMLs to TXT\nfrom tqdm.auto import tqdm\n\ndef parse_all_pdfs_xmls(pdf_dir, xml_dir, parsed_dir):\n    pdf_files = list(pdf_dir.glob('*.pdf'))\n    if not pdf_files and not xml_dir.exists():\n        raise ValueError(\"No PDF or XML files found.\")\n\n    parsed_dir.mkdir(parents=True, exist_ok=True)\n\n    # PDF → TXT\n    for pdf in tqdm(pdf_files, desc=\"PDF→TXT\"):\n        try:\n            pdf2text(pdf, parsed_dir)\n        except Exception as e:\n            print(f\"PDF error {pdf.stem}: {e}\")\n\n    # XML → TXT (append mode)\n    if xml_dir.exists():\n        for xml in tqdm(xml_dir.glob('*.xml'), desc=\"XML→TXT\"):\n            try:\n                txt = xml2text(xml).encode(\"utf8\")\n                out = parsed_dir / f\"{xml.stem}.txt\"\n                with open(out, \"ab\") as f:  # 'ab' = append binary\n                    f.write(txt)\n                    f.write(b\"\\n\")\n            except Exception as e:\n                print(f\"XML error {xml.stem}: {e}\")\n    print(\"Done parsing to text.\")\n\nparse_all_pdfs_xmls(PDF_DIR, XML_DIR, OUT_DIR)","metadata":{"_cell_guid":"98be0899-3cad-423b-a3db-313209068df0","_uuid":"84859532-6acd-4011-b783-d0d24257a19b","collapsed":false,"execution":{"iopub.status.busy":"2025-08-01T03:49:29.384265Z","iopub.execute_input":"2025-08-01T03:49:29.384598Z","iopub.status.idle":"2025-08-01T03:49:31.041735Z","shell.execute_reply.started":"2025-08-01T03:49:29.38457Z","shell.execute_reply":"2025-08-01T03:49:31.040864Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.014728,"end_time":"2025-07-30T12:43:50.888086","exception":false,"start_time":"2025-07-30T12:43:50.873358","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /tmp/src/check_parse.py\nimport polars as pl\nfrom pathlib import Path\nfrom helpers import *\n\nl=get_logger()\n\ndef gt_dataset_id_normalization(name:str) -> pl.Expr:\n    return (\n        pl.when(is_doi_link(name))\n        .then(pl.col(name).str.split(DOI_LINK).list.last())\n        .otherwise(name)\n        .str.to_lowercase()\n    )\n\ndef main():\n    if IS_KAGGLE_SUBMISSION:\n        l.debug('skipping check_parse for submission')\n        return\n    df = (\n        get_df('/tmp/train_parse')\n        .with_columns(pl.col('text').str.replace_all('\\s+', '').str.to_lowercase().alias('text'))\n    )\n\n    gt = (\n        pl.read_csv(COMP_DIR/'train_labels.csv')\n        .filter(pl.col('article_id').is_in(df['article_id']))\n        .filter(pl.col('type')!='Missing')\n        .with_columns(gt_dataset_id_normalization('dataset_id').alias('norm_id'))\n    )\n\n    l.info(f\"pymupdf misses: {gt.join(df, on='article_id').with_columns(hit=pl.col('text').str.contains(pl.col('norm_id'), literal=True)).filter(~pl.col('hit')).height} dataset_ids\")\n\nif __name__=='__main__': main()","metadata":{"_cell_guid":"01632e8b-2a68-4dec-9606-f91214a8c020","_uuid":"5210e49f-e5ab-45c6-b673-f0bd08dc1877","collapsed":false,"execution":{"iopub.status.busy":"2025-08-01T03:49:31.043614Z","iopub.execute_input":"2025-08-01T03:49:31.043846Z","iopub.status.idle":"2025-08-01T03:49:31.056043Z","shell.execute_reply.started":"2025-08-01T03:49:31.043828Z","shell.execute_reply":"2025-08-01T03:49:31.055301Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.016232,"end_time":"2025-07-30T12:43:50.913072","exception":false,"start_time":"2025-07-30T12:43:50.89684","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /tmp/src/getid.py\nimport re\nimport polars as pl\nfrom typing import Optional, Tuple\n\nfrom helpers import *\n\nimport re\n\nCOMPILED_PATTERNS = {\n    # 参考文献見出しの多様化と空白文字の柔軟対応\n    'ref_header_patterns': [\n        re.compile(r'\\b(R\\s*E\\s*F\\s*E\\s*R\\s*E\\s*N\\s*C\\s*E\\s*S|BIBLIOGRAPHY|LITERATURE CITED|WORKS CITED|CITED WORKS)\\b[:\\s]*', re.IGNORECASE),\n        re.compile(r'\\b(REFERENCES|BIBLIOGRAPHY|LITERATURE\\s*CITED|WORKS\\s*CITED|CITED\\s*WORKS)\\b', re.IGNORECASE),\n    ],\n\n    # 引用パターンの拡張（番号リスト、範囲、著者名＋年、DOIなど）\n    'citation_pattern': re.compile(\n        r'^\\s*('\n        r'\\[\\d+(-\\d+)?(,\\s*\\d+(-\\d+)?)*\\]'                  # [1], [12-15], [1,3,5-7]\n        r'|\\([A-Z][a-z]+ et al\\., \\d{4}\\)'                  # (Smith et al., 2020)\n        r'|doi:\\s*10\\.\\d{4,9}/[-._;()/:A-Z0-9]+'            # doi:10.xxxx/xxxxx\n        r'|https?://doi\\.org/10\\.\\d{4,9}/[-._;()/:A-Z0-9]+' # https://doi.org/10.xxxx/xxxxx\n        r'|\\d+\\.|\\d+\\)|\\(\\d+\\)|\\d+(?=\\s|$)'                  # 1. 1) (1) 1（単純番号）\n        r')\\s*', re.IGNORECASE),\n\n    # 最初の引用パターンも必要に応じて拡張可能\n    'first_citation_patterns': [\n        re.compile(r'^\\s*\\[1\\]\\s*'),\n        re.compile(r'^\\s*\\(1\\)\\s*'),\n        re.compile(r'^\\s*1\\.\\s*'),\n        re.compile(r'^\\s*1\\)\\s*'),\n        re.compile(r'^\\s*1(?=\\s|$)'),\n        # 例: 著者名＋年の最初の引用パターン追加も可能\n        re.compile(r'^\\s*\\([A-Z][a-z]+ et al\\., 20\\d{2}\\)'),\n    ],\n}\n\n\nl = get_logger()\n\ndef find_last_reference_header(text: str, header_patterns: list[re.Pattern]) -> Optional[int]:\n    last_match_idx = None\n    for pattern in header_patterns:\n        matches = list(pattern.finditer(text))\n        if matches:\n            last_match_idx = matches[-1].start()\n    return last_match_idx\n\ndef find_last_first_citation(text: str) -> Optional[int]:\n    lines = text.splitlines()\n    last_match_line = None\n    for line_num, line in enumerate(lines):\n        line = line.strip()\n        for pattern in COMPILED_PATTERNS['first_citation_patterns']:\n            if pattern.match(line):\n                next_lines = lines[line_num:line_num+3]\n                if any(COMPILED_PATTERNS['citation_pattern'].match(l.strip()) for l in next_lines[1:]):\n                    last_match_line = line_num\n                break\n    return last_match_line\n\nfrom typing import Optional\n\n# 補助関数：誤検出行（ノイズ行）を判定する関数\ndef is_noise_line(line: str) -> bool:\n    stripped = line.strip()\n    if not stripped:\n        return True  # 空行はノイズとみなす\n\n    # 区切り線（---, ===, ***など）\n    if stripped in ['---', '===', '***']:\n        return True\n\n    # ページ番号のような行例: \"Page 12\"\n    if stripped.lower().startswith('page ') and stripped[5:].strip().isdigit():\n        return True\n\n    # FigureやTableのラベル行を除外（例: Figure 1, Table 2）\n    if stripped.lower().startswith('figure ') or stripped.lower().startswith('table '):\n        return True\n\n    return False\n\ndef find_reference_start(text: str) -> Optional[int]:\n    lines = text.splitlines()\n\n    # ① 見出し検出：COMPILED_PATTERNS['ref_header_patterns']のどれかにマッチすれば検出\n    for i, line in enumerate(lines):\n        for pattern in COMPILED_PATTERNS['ref_header_patterns']:\n            if pattern.search(line):\n                # 見出しの次数行で空行・ノイズ行をスキップして最初の有効行を返す\n                for offset in range(1, 6):\n                    idx = i + offset\n                    if idx >= len(lines):\n                        break\n                    candidate_line = lines[idx].strip()\n                    if candidate_line and not is_noise_line(candidate_line):\n                        return idx\n                # 見出し直後に該当行がなければ見出し行+1を返す\n                return i + 1\n\n    # ② 既存の最後の初出引用位置を試す\n    last_first_citation = find_last_first_citation(text)\n    if last_first_citation is not None:\n        return last_first_citation\n\n    # ③ 後半から引用パターンの連続行を探す\n    start_search_idx = int(len(lines) * 0.5)\n    for i in range(start_search_idx, len(lines)):\n        line = lines[i].strip()\n        if is_noise_line(line) or len(line) < 5:\n            continue\n        if COMPILED_PATTERNS['citation_pattern'].match(line):\n            next_lines = lines[i:i + 5]\n            count = sum(1 for l in next_lines if COMPILED_PATTERNS['citation_pattern'].match(l.strip()))\n            if count >= 3:\n                # 直前の引用ではない行を探す（最大15行前まで）\n                for j in range(i, max(-1, i - 15), -1):\n                    prev_line = lines[j].strip()\n                    if prev_line and not COMPILED_PATTERNS['citation_pattern'].match(prev_line) and not is_noise_line(prev_line):\n                        return j + 1\n                return max(0, i - 15)\n\n    return None\n\n\n\ndef split_text_and_references(text: str) -> Tuple[str, str]:\n    header_idx = find_last_reference_header(text, COMPILED_PATTERNS['ref_header_patterns'])\n    prev_idx = None\n    while header_idx is not None and header_idx != prev_idx:\n        prev_idx = header_idx\n        header_idx = find_last_reference_header(text[:header_idx].strip(), COMPILED_PATTERNS['ref_header_patterns'])\n    if prev_idx is not None:\n        return text[:prev_idx].strip(), text[prev_idx:].strip()\n\n    ref_start_line = find_reference_start(text)\n    if ref_start_line is not None:\n        lines = text.splitlines()\n        body = '\\n'.join(lines[:ref_start_line])\n        refs = '\\n'.join(lines[ref_start_line:])\n        return body.strip(), refs.strip()\n\n    return text.strip(), ''\n\ndef get_splits(df: pl.DataFrame) -> pl.DataFrame:\n    bodies, refs = [], []\n    for raw_text in df['text']:\n        main, ref = split_text_and_references(raw_text)\n        bodies.append(main)\n        refs.append(ref)\n    return df.with_columns(pl.Series('body', bodies), pl.Series('ref', refs))\n\ndef tidy_extraction(df) -> pl.DataFrame:\n    bad_ids = [f'{DOI_LINK}{e}' for e in ['10.5061/dryad', '10.5281/zenodo', '10.6073/pasta']]\n\n    doi_df = (\n        df.with_columns(pl.col('body').str.extract_all(r'10\\s*\\.\\s*\\d{4,9}\\s*/\\s*\\S+').alias('match'))\n          .explode('match')\n          .drop_nulls('match')\n          .with_columns(\n              pl.col('match').str.replace_all(r'\\s+', '')\n                             .str.replace(r'[^A-Za-z0-9]+$', '')\n                             .str.to_lowercase()\n                             .alias('dataset_id')\n          )\n          .group_by('article_id', 'dataset_id')\n          .agg('match')\n          .with_columns((DOI_LINK + pl.col('dataset_id')).alias('dataset_id'))\n    )\n\n    REGEX_IDS = (\n    r\"(?i)\\b(?:\"\n    r\"CHEMBL\\s*\\d+|\"\n    r\"E-GEOD-\\s*\\d+|E-PROT-\\s*\\d+|E-MTAB-\\s*\\d+|E-MEXP-\\s*\\d+|EMPIAR-\\s*\\d+|\"\n    r\"ENSBTAG\\s*\\d+|ENSOARG\\s*\\d+|\"\n    r\"EPI\\s*_?\\s*ISL\\s*_?\\s*\\d{5,}|EPI\\s*\\d{6,7}|\"\n    r\"HPA\\s*\\d+|CP\\s*\\d{6}|IPR\\s*\\d{6}|PF\\s*\\d{5}|BX\\s*\\d{6}|KX\\s*\\d{6}|K0\\s*\\d{4}|CAB\\s*\\d{6}|\"\n    r\"NC\\s*_\\s*\\d{6}\\.\\d{1}|NM\\s*_\\s*\\d{9}|\"\n    r\"PRJNA\\s*\\d+|PRJDB\\s*\\d+|PRJEB\\s*\\d+|PXD\\s*\\d+|SAMN\\s*\\d+|\"\n    r\"GSE\\s*\\d+|GSM\\s*\\d+|\"\n    r\"CVCL\\s*_\\s*[A-Z0-9]{4}|\"\n    r\"PDB\\s*[1-9][A-Z0-9]{3}|HMDB\\s*\\d+|\"\n    r\"dryad\\.\\s*[^\\s\\\"<>]+|pasta\\/\\s*[^\\s\\\"<>]+|\"\n    r\"(?:SR[RPAX]|STH|ERR|DRR|DRX|DRP|ERP|ERX)\\d+|\"\n    r\"phs\\d{6}(?:\\.v\\d{1,2}\\.p\\d{1,2})?|\"   # dbGaP accession\n    r\"MTBLS\\d+|\"                            # MetaboLights\n    r\"E-[A-Z]{4}-\\d+|\"                      # ArrayExpress (general)\n    r\"ds\\d{6}|\"                             # OpenNeuro\n    r\"[1-5]\\s*\\.(?:10|20|30|40|50|60|70|80|90)\\s*\\.\\d{2,4}\\s*\\.\\d{2,4}\"  # numeric DOI-like\n    r\")\"\n)\n\n\n\n\n    \n    acc_df = (\n        df.with_columns(\n            pl.col('text').str.extract_all(REGEX_IDS).alias('match')\n        )\n        .explode('match')\n        .drop_nulls('match')\n        .with_columns(\n            pl.col('match').str.replace_all(r'\\s+', '')\n                           .str.replace(r'[^A-Za-z0-9]+$', '')\n                           .str.replace(r'(?i)^PDB', '')\n                           .alias('dataset_id')\n        )\n        .group_by('article_id', 'dataset_id')\n        .agg('match')\n        .with_columns(\n            pl.when(pl.col('dataset_id').str.starts_with('dryad.'))\n              .then(f'{DOI_LINK}10.5061/' + pl.col('dataset_id'))\n              .otherwise('dataset_id')\n              .alias('dataset_id')\n        )\n        .with_columns(\n            pl.when(pl.col('dataset_id').str.starts_with('pasta/'))\n              .then(f'{DOI_LINK}10.6073/' + pl.col('dataset_id'))\n              .otherwise('dataset_id')\n              .alias('dataset_id')\n        )\n    )\n\n    df = pl.concat([doi_df, acc_df])\n\n    df = (\n        df.unique(['article_id', 'dataset_id'])  # CHANGED\n          .filter(~pl.col('article_id').str.replace('_','/').str.contains(pl.col('dataset_id').str.split(DOI_LINK).list.last().str.escape_regex()))\n          .filter(~pl.col('dataset_id').str.contains(pl.col('article_id').str.replace('_','/').str.escape_regex()))\n          .filter(~pl.col('dataset_id').str.contains('figshare', literal=True))\n          .filter(~pl.col('dataset_id').is_in(bad_ids))\n          .filter(\n              pl.when(is_doi_link('dataset_id') &\n                      (pl.col('dataset_id').str.split('/').list.last().str.len_chars() < 5))\n               .then(False)\n               .otherwise(True)\n          )\n          .with_columns(pl.col('match').list.unique())\n    )\n    return df\n\ndef get_context_window(text: str, substring: str, window: int = 100) -> str:\n    idx = text.find(substring)\n    if idx == -1:\n        raise ValueError\n    start = max(idx - window, 0)\n    end = min(idx + len(substring) + window, len(text))\n    return text[start:end]\n\ndef get_window_df(text_df, ids_df):\n    df = ids_df.join(text_df, on='article_id')\n    windows = []\n    for text, match_ids in df.select('text', 'match').rows():\n        windows.append(get_context_window(text, match_ids[0]))\n    return df.with_columns(pl.Series('window', windows)).select('article_id', 'dataset_id', 'window')\n\ndef main():\n    text_df = get_df('/tmp/train_parse')\n    df = get_splits(text_df)\n    df = tidy_extraction(df)\n    df = get_window_df(text_df, df)\n    df.write_parquet('/tmp/extracted.parquet')\n    df = assume_type(df)\n    df.select(['article_id', 'dataset_id', 'type']).with_row_index(name='row_id').write_csv('/kaggle/working/submission.csv')\n    if not IS_KAGGLE_SUBMISSION:\n        results = evaluate(df)\n        for r in results: l.info(r)\n        results = evaluate(df, on=['article_id', 'dataset_id', 'type'])\n        for r in results: l.info(r)\n\nif __name__=='__main__': main()","metadata":{"_cell_guid":"83084a3e-ab3e-4c24-9045-7bc81df72e34","_uuid":"5a79e391-1a5c-4264-9aa5-747cb657a266","collapsed":false,"execution":{"iopub.status.busy":"2025-08-01T03:49:31.056944Z","iopub.execute_input":"2025-08-01T03:49:31.057175Z","iopub.status.idle":"2025-08-01T03:49:31.070338Z","shell.execute_reply.started":"2025-08-01T03:49:31.057148Z","shell.execute_reply":"2025-08-01T03:49:31.069697Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.019717,"end_time":"2025-07-30T12:43:50.939863","exception":false,"start_time":"2025-07-30T12:43:50.920146","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /tmp/src/llm_validate.py\nimport polars as pl\nimport os\n\nfrom helpers import *\n\nl = get_logger()\n\n# ===============================\n# Few-shot 強化済みプロンプト + 文脈パターン明示 + アクセッション例追加\n# ===============================\nSYS_PROMPT_CLASSIFY_DOI = \"\"\"\n1. Priority Rules (highest → lowest)\n\n1.1 Always classify as A (Data) if:\nDOI prefix matches a known data repository:\n\nDryad: 10.5061\nZenodo: 10.5281\nFigshare: 10.6084\nMendeley Data: 10.24433/, 10.17632\nDataverse: 10.7910/DVN\nOpenNeuro: 10.18112/openneuro.\nPANGAEA: 10.1594/PANGAEA.\nNeotoma Paleoecology: 10.21233\nICPSR: 10.3886\nNOAA NCEI: 10.7289\nUK Data Service: 10.5255\nEMPIAR: 10.6019\n\nNon-DOI dataset accession prefixes:\nNCBI SRA / ENA: SRP, SRA, ERP, ERX\nBioProject: PRJNA, PRJEB, PRJDB, SAMN\nProteomeXchange / PRIDE: PXD\nArrayExpress / EMBL-EBI: E-MTAB, E-\nMetaboLights: MTBLS\nGEO Series: GSE\nGenBank: MN, NC_, CP, MT (context needed)\nEMDB: EMD-\nEMPIAR: EMPIAR-\n\n1.2 Context keywords trigger A (Data)\nIf the context contains any of the following patterns → classify as A:\n- hosted on\n- deposited at\n- available via\n- uploaded to\n- stored on\n- accessible via\n- provided by\n- deposited in\n- archived at\n- supplementary dataset / supporting dataset\n- experimental data / raw data\n\n2. Classify as B (Literature) if:\nDOI prefix belongs to a publisher (e.g., 10.1038, 10.1007, etc.).\nContext patterns → classify as B:\n- published in\n- as described in\n- reported in\n- method details published in\n- supplementary material / supplementary information only\n\n3. Ambiguous cases\nNo repository prefix and no clear context → default to B.\nRare accession formats → rely on context keywords.\n\n4. Output\nOnly output:\nA → data repository / dataset\nB → literature / non-data resource\n\n5. Few-shot examples (アクセッション例追加, 文脈パターン明示, 25 件以上)\n“Raw images are hosted on Figshare (DOI 10.6084/m9.figshare.1234567).” → A\n“Sequence reads deposited at BioProject accession PRJNA765432.” → A\n“Method details published in J. Proteome Res. DOI: 10.1021/acs.jproteome.0c00845.” → B\n“As described in Nature Methods (DOI 10.1038/s41592-020-0793-2).” → B\n“See Supplementary Data available via Zenodo (10.5281/zenodo.987654).” → A\n“Data uploaded to Dryad (10.5061/dryad.x1y2z3).” → A\n“Referenced paper reported in bioRxiv DOI 10.1101/2020.01.01.123456.” → B\n“Metabolomics data in MetaboLights MTBLS1234.” → A\n“The MRI scans are deposited at OpenNeuro (DOI 10.18112/openneuro.ds000001.v1.0.0).” → A\n“Protein structure described in Science (DOI 10.1126/science.abc1234).” → B\n“Microbiome raw data hosted on ArrayExpress E-MTAB-9876.” → A\n“RNA sequencing reads available via SRA SRP098765.” → A\n“Supplementary tables published in Nature Genetics (DOI 10.1038/ng.123456).” → B\n“Data from neuroimaging study uploaded to OpenNeuro.” → A\n“Proteomics dataset deposited at PRIDE PXD012345.” → A\n“Sequencing metadata hosted on Zenodo.” → A\n“Results presented in conference proceedings (DOI 10.1109/ICML.2020.12345).” → B\n“GenBank accession MN1234567 contains raw sequences.” → A\n“Cryo-EM map deposited at EMDB EMD-9876.” → A\n“Clinical trial dataset uploaded to Dryad.” → A\n“Experimental raw data in MetaboLights MTBLS5678.” → A\n“Supplementary figures published in Science (DOI 10.1126/science.abc12345).” → B\n“Raw imaging files stored on Figshare.” → A\n“Referenced preprint DOI 10.1101/2021.01.01.123456.” → B\n“Data portal provides access to large-scale RNA-seq datasets.” → A\n“Study reported in Nature Communications (DOI 10.1038/s41467-020-12345).” → B\n“SAMN123456 metadata contains raw sequences from microbiome study.” → A\n\"\"\".strip()\n\n# ===============================\n# データフレーム構築\n# ===============================\ndef build_df():\n    df = pl.read_parquet('/tmp/extracted.parquet')\n    df.filter(~is_doi_link('dataset_id')).select('article_id', 'dataset_id').write_csv('/tmp/accid_sub.csv')\n    return df.filter(is_doi_link('dataset_id'))\n\n# ===============================\n# プロンプト作成\n# ===============================\ndef build_prompt(tokenizer, df):\n    prompts = []\n    for doi, text in df.select('dataset_id', 'window').rows():\n        messages = [{'role':'system','content': SYS_PROMPT_CLASSIFY_DOI},\n                    {'role':'user', 'content': text}]\n        prompts.append(tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False))\n    return df.with_columns(pl.Series('prompt', prompts))\n\n# ===============================\n# メイン処理\n# ===============================\nif __name__=='__main__':\n    os.environ[\"VLLM_USE_V1\"] = \"0\"\n    import vllm\n    from logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\n\n    model_path = \"/kaggle/input/qwen2.5/transformers/32b-instruct-awq/1\"\n    llm = vllm.LLM(\n        model_path,\n        quantization='awq',\n        tensor_parallel_size=2,\n        gpu_memory_utilization=0.9,\n        trust_remote_code=True,\n        dtype=\"half\",\n        enforce_eager=True,\n        max_model_len=2048,\n        disable_log_stats=True,\n        disable_custom_all_reduce=True,\n        enable_prefix_caching=True,\n        task='generate'\n    )\n\n    tokenizer = llm.get_tokenizer()\n    df = build_df()\n    df = build_prompt(tokenizer, df)\n    prompts = df['prompt'].to_list()\n\n    mclp = MultipleChoiceLogitsProcessor(tokenizer, choices=[\"A\", \"B\"])\n    outputs = llm.generate(\n        prompts,\n        vllm.SamplingParams(\n            seed=777,\n            temperature=0,\n            skip_special_tokens=True,\n            max_tokens=1,\n            logits_processors=[mclp],\n            logprobs=len(mclp.choices)\n        ),\n        use_tqdm=True\n    )\n\n    logprobs = [\n        {lp.decoded_token: lp.logprob for lp in list(lps)}\n        for lps in [output.outputs[0].logprobs[0].values() for output in outputs]\n    ]\n    choices = [max(d, key=d.get) for d in logprobs]\n    types = {'A': True, 'B': False}\n    choices = [types[c] for c in choices]\n\n    df = df.with_columns(pl.Series('type', choices))\n    df.filter(pl.col('type')).select('article_id', 'dataset_id').write_csv('/tmp/doi_sub.csv')\n    df = pl.concat([pl.read_csv('/tmp/doi_sub.csv'), pl.read_csv('/tmp/accid_sub.csv')])\n    df = assume_type(df)\n    df.select(['article_id', 'dataset_id', 'type']).with_row_index(name='row_id').write_csv('/kaggle/working/submission.csv')\n\n    if not IS_KAGGLE_SUBMISSION:\n        results = evaluate(df)\n        for r in results:\n            l.info(r)\n        results = evaluate(df, on=['article_id', 'dataset_id', 'type'])\n        for r in results:\n            l.info(r)\n","metadata":{"_cell_guid":"af30506a-e45e-4a3b-ba81-23dd154bde8d","_uuid":"94fc4779-0b43-4058-ac64-f54a7ebd8a76","collapsed":false,"execution":{"iopub.status.busy":"2025-08-01T03:49:31.071193Z","iopub.execute_input":"2025-08-01T03:49:31.071381Z","iopub.status.idle":"2025-08-01T03:49:31.085361Z","shell.execute_reply.started":"2025-08-01T03:49:31.071365Z","shell.execute_reply":"2025-08-01T03:49:31.084469Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.019658,"end_time":"2025-07-30T12:43:50.971551","exception":false,"start_time":"2025-07-30T12:43:50.951893","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /tmp/src/post_filter.py\nimport polars as pl\nfrom helpers import *\n\n\"\"\"\nFourth essence: Post-filter to cut FP DOIs that look like literature.\n- Read /kaggle/working/submission.csv (output of llm_validate.py)\n- Join with /tmp/extracted.parquet to get context window\n- Drop DOI rows that (1) start with typical publisher prefixes AND (2) have no data-ish words nearby\n- Keep accessions untouched\n\"\"\"\n\nl = get_logger()\n\nPAPER_PREFIXES = [\n    \"10.5061\",\"10.5281\",\"10.17632\",\"10.1594\",\"10.15468\",\"10.17882\",\"10.7937\",\"10.7910\",\"10.6073\",\n    \"10.3886\",\"10.3334\",\"10.4121\",\"10.5066\",\"10.5067\",\"10.18150\",\"10.25377\",\"10.25387\",\"10.23642\",\"10.24381\",\"10.22033\"\n]\n\nCONTEXT_RE = r\"(?i)\\b(data(?:set)?|repository|archive|deposited|available|supplementary|raw(?:\\s+data)?|uploaded|hosted|stored|accession)\\b\"\n\ndef remove_extra_digit(df: pl.DataFrame, column: str) -> pl.DataFrame:\n    \"\"\"\n    Remove rows where the value in `column` is just the same DOI with one extra digit at the end.\n    Keeps all other columns.\n    \"\"\"\n    items_set = set(df[column].to_list())\n\n    def keep_row(value):\n        if (value[-1].isdigit() and value[:-1] in items_set) or \\\n           (len(value) > 2 and value[-2:].isdigit() and value[:-2] in items_set):\n            return False\n        return True\n\n    return df.filter(pl.col(column).map_elements(keep_row, return_dtype=pl.Boolean))\ndef is_paper_prefix(col: str = \"dataset_id\") -> pl.Expr:\n    expr = pl.lit(False)\n    for p in PAPER_PREFIXES:\n        expr = expr | pl.col(col).str.starts_with(f\"{DOI_LINK}{p}\")\n    return expr\n\ndef main():\n    sub = pl.read_csv(\"/kaggle/working/submission.csv\")\n\n    # Normalize columns: drop row_id if present so concat widths match\n    if \"row_id\" in sub.columns:\n        sub = sub.drop(\"row_id\")\n\n    # Context windows\n    win = pl.read_parquet(\"/tmp/extracted.parquet\").select(\"article_id\", \"dataset_id\", \"window\")\n\n    # DOI & ACC split\n    doi_rows = sub.filter(is_doi_link(\"dataset_id\")).join(win, on=[\"article_id\", \"dataset_id\"], how=\"left\")\n    acc_rows = sub.filter(~is_doi_link(\"dataset_id\"))\n\n    keep_mask = (\n        (~is_paper_prefix(\"dataset_id\"))  # not a known paper prefix\n        | doi_rows[\"window\"].fill_null(\"\").str.contains(CONTEXT_RE)\n    )\n\n    kept_doi = doi_rows.filter(keep_mask).select(\"article_id\", \"dataset_id\", \"type\")\n    doi_df = remove_extra_digit(kept_doi, \"dataset_id\")\n    final = pl.concat([doi_df, acc_rows.select(\"article_id\", \"dataset_id\", \"type\")])\n\n    # Re-eval & save\n    if not IS_KAGGLE_SUBMISSION:\n        for r in evaluate(final): l.info(r)\n        for r in evaluate(final, on=[\"article_id\", \"dataset_id\", \"type\"]): l.info(r)\n\n    final.with_row_index(\"row_id\").write_csv(\"/kaggle/working/submission.csv\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2025-08-01T03:49:31.086302Z","iopub.execute_input":"2025-08-01T03:49:31.086528Z","iopub.status.idle":"2025-08-01T03:49:31.097894Z","shell.execute_reply.started":"2025-08-01T03:49:31.086488Z","shell.execute_reply":"2025-08-01T03:49:31.097246Z"},"papermill":{"duration":0.018508,"end_time":"2025-07-30T12:43:51.002131","exception":false,"start_time":"2025-07-30T12:43:50.983623","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /tmp/src/post_validate.py\n\nfrom helpers import *\nimport polars as pl\nimport os\n\n\nl = get_logger()\n\n\nPROMPT_CLASSIFY_CITATION_TYPE = '''\n# Role & Task\nYou are an expert data citation analyst. Your task is to classify a given citation from a scientific paper into one of two categories: **A** (Data) or **B** (Not Data). Base your decision strictly on the provided abstract and the context of the citation.\n\n## Instructions\n1.  **Read the provided abstract** to understand the research context.\n2.  **Analyze the citation context** for key linguistic cues.\n3.  **Classify the citation** as either **A** or **B** based on the definitions below.\n4.  **Output only a single letter: A or B.** Do not output any other text, explanation, or formatting.\n\n## Category Definitions\n\n### **Category A: DATA**\nThe citation points to a dataset. This includes:\n*   **Primary Data:** Raw or processed data that the current study's authors collected, generated, or created.\n*   **Secondary Data:** Data that was originally produced by other researchers but is being *used as a dataset* in the current study.\n*   **Key Phrases:** \"data are available at\", \"we collected\", \"we measured\", \"data were obtained from\", \"dataset\", \"downloaded from\", \"deposited in\", repository names (e.g., GenBank, Zenodo, Figshare, TCIA).\n\n### **Category B: NOT DATA**\nThe citation points to a traditional scholarly publication or other non-data resource. This includes:\n*   Journal articles, books, conference proceedings, preprints, protocols, methods papers.\n*   **Key Phrases:** \"as described in\", \"according to\", \"previous study\", \"et al.\", \"paper\", \"article\", \"methodology\", \"was used for analysis\" (without indicating data access).\n*   Citations that provide background context or methodological description but do not serve as the source of the data used in the analysis.\n\n## Input Format\nYou will be provided with the following three pieces of information:\nPaper Abstract: {abstract}\nCitation: {dataset_id}\nCitation Context: {context}\n\n## Critical Thinking Guidelines\n*   A DOI or URL can point to either data (A) or a paper (B). The context determines the classification.\n*   If the citation is used to describe the *source* of the data for the current study's analysis, it is likely **A**.\n*   If the citation is used to provide background, justify a method, or compare results, it is likely **B** (a reference to another paper).\n*   When in doubt, rely on the linguistic cues in the \"Citation Context\".\n\n## Examples for Pattern Recognition\n\n**Example 1 (Classify as A):**\n*   Context: \"Three out of four cohorts used in this study can be found on The Cancer Imaging Archive (TCIA)24: Canadian benchmark dataset23: https://doi.org/10.7937/K9/TCIA.2017.8oje5q00.\"\n*   **Reasoning:** The text states cohorts are \"used in this study\" and provides direct repository links. This is a clear case of citing external data for use.\n*   **Output:** A\n\n**Example 2 (Classify as B):**\n*   Context: \"data presented here are available at the SEANOE dataportal: https://doi.org/10.17882/94052 (ZooScan dataset Grandremy et al. 2023c)\"\n*   **Reasoning:** The phrase \"data presented here\" indicates this is the authors' own data being deposited, not a citation to an external source they are using. The \"(Author et al. Year)\" format is a classic literature citation style.\n*   **Output:** B\n\n**Example 3 (Classify as A):**\n*   Context: \"GBIF occurrence data: Vulpes vulpes: https://doi.org/10.15468/dl.wgtneb (28 May 2021).\"\n*   **Reasoning:** Explicitly names the data source (GBIF) and provides a direct access link/DOI for the specific dataset used.\n*   **Output:** A\n\n**Example 4 (Classify as B):**\n*   Context: \"North American soil NCBI SRA SRP035367 Smith & Peay [36] ITS2-Soil\"\n*   **Reasoning:** While it mentions a data repository ID (SRP035367), it couples it with a standard literature citation \"[36]\". The context suggests it is referencing the *paper* by Smith & Peay that describes the data, not directly citing the dataset itself for use.\n*   **Output:** B\n\n## Ready for Input\nBegin your analysis. Remember: Output only **A** or **B**.\n'''\n\ndef get_context_window(text: str, substring: str, window: int = 600) -> str:\n    idx = text.find(substring)\n    if idx == -1:\n        return \"no context\", \"no abstraction\"\n    start = max(idx - window, 0)\n    end = min(idx + len(substring) + window, len(text))\n    return text[start:end] , text[:1000]\n\n\n\n\ndef find_context_win(tokenizer,df):\n    text_df = pl.read_parquet('/tmp/context_data.parquet')\n    # print(text_df)\n    df = df.join(text_df, on=[\"article_id\",\"dataset_id\"], how=\"inner\")\n    df = df.drop(\"type\")\n    print(df)\n\n    prompts = []\n    \n    for article_id,dataset_id,text,match in df.select([\"article_id\",\"dataset_id\",\"text\",'match']).rows():\n\n        context, abstract = get_context_window(text,match)\n        user_content = f\"\"\"\n        Paper Abstract: {abstract}\n        \n        Citation: {dataset_id}\n\n        \n        Citation Context: {context}\n        \"\"\"\n        messages = [\n            {\"role\": \"system\", \"content\": PROMPT_CLASSIFY_CITATION_TYPE},\n            {\"role\": \"user\", \"content\": user_content.strip()}\n        ]\n        prompts.append(\n            tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n        )\n        \n    return df.with_columns(pl.Series(\"prompt\", prompts))\n\n    \n\nif __name__==\"__main__\":\n    os.environ[\"VLLM_USE_V1\"] = \"0\"\n    MODEL_PATH = \"/kaggle/input/qwen2.5/transformers/32b-instruct-awq/1\"\n    import vllm\n    from logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\n\n    llm = vllm.LLM(\n        MODEL_PATH,\n        quantization='awq',\n        tensor_parallel_size=2,\n        gpu_memory_utilization=0.9,\n        trust_remote_code=True,\n        dtype=\"half\",\n        enforce_eager=True,\n        max_model_len=16384,\n        disable_log_stats=True, \n        disable_custom_all_reduce=True,\n        enable_prefix_caching=True,\n        task='generate')\n\n    tokenizer = llm.get_tokenizer()\n\n    df=pl.read_csv(\"/kaggle/working/submission.csv\")\n    \n    if \"row_id\" in df.columns:\n        df = df.drop(\"row_id\")\n\n    # print(df)\n\n    doi_df = df.filter(is_doi_link(\"dataset_id\"))\n    acc_df = df.filter(~is_doi_link(\"dataset_id\"))\n\n    # print(doi_df)\n\n    df = find_context_win(tokenizer,doi_df)\n\n    \n    \n    prompts = df['prompt'].to_list()\n    mclp = MultipleChoiceLogitsProcessor(tokenizer, choices=[\"A\", \"B\",\"C\"])\n    outputs = llm.generate(prompts, vllm.SamplingParams(seed=777, temperature=0.7, skip_special_tokens=True, max_tokens=1, logits_processors=[mclp], logprobs=len(mclp.choices)), use_tqdm=True)\n    logprobs = [{lp.decoded_token: lp.logprob for lp in list(lps)} for lps in [output.outputs[0].logprobs[0].values() for output in outputs]]\n    choices = [max(d, key=d.get) for d in logprobs]\n    types = {'A': True, 'B': False}\n    choices = [types[c] for c in choices]\n    df = df.with_columns(pl.Series('type', choices))\n    df.filter(pl.col('type')).select('article_id', 'dataset_id').write_csv('/tmp/doi_sub.csv')\n    df = pl.concat([pl.read_csv('/tmp/doi_sub.csv'), pl.read_csv('/tmp/accid_sub.csv')])\n    df = assume_type(df)\n    df.select(['article_id', 'dataset_id', 'type']).with_row_index(name='row_id').write_csv('/kaggle/working/submission.csv')\n    # print(df)\n    if not IS_KAGGLE_SUBMISSION:\n        results = evaluate(df)\n        for r in results: l.info(r) \n        results = evaluate(df, on=['article_id', 'dataset_id', 'type'])\n        for r in results: l.info(r)\n    \n    \n    try:\n        del llm, tokenizer\n    except:\n        pass\n    \n    import gc, torch\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /tmp/src/predict.py\n\nfrom helpers import *\nimport polars as pl\nimport os\n\n\nl = get_logger()\n\n\nPROMPT_CLASSIFY_CITATION_TYPE = '''\n# Role & Task\nYou are an expert data citation analyst. Your task is to classify a given citation from a scientific paper into one of two categories based on the context: **A (Primary Data)** or **B (Secondary Data)**.\n\n## Instructions\n1.  **Read the provided abstract** to understand the research context.\n2.  **Analyze the citation context** for key linguistic cues.\n3.  **Classify the citation** as either **A** or **B** based on the definitions below.\n4.  **Output only a single letter: A or B.** Do not output any other text, explanation, or formatting.\n\n## Category Definitions\n\n### **Category A: PRIMARY DATA**\nThe data was generated, collected, or created by the **authors of the current study**. This is *their* data.\n*   **Key Phrases:** \"we collected\", \"we generated\", \"our data\", \"data are available at [URL/DOI]\", \"data have been deposited\", \"this study presents\", \"supplementary data\".\n\n### **Category B: SECONDARY DATA**\nThe data was produced by **other researchers** or external sources and is being reused or analyzed by the current study's authors.\n*   **Key Phrases:** \"data were obtained from\", \"publicly available data\", \"previously published data\", \"retrieved from\", \"downloaded from\", \"[Dataset Name] dataset\", \"database\", citing a specific external source.\n\n## Input Format\nYou will be provided with the following three pieces of information:\nPaper Abstract: {abstract}\nCitation: {dataset_id}\nCitation Context: {context}\n\n\n## Decision Framework\nAnswer these questions based on the **Citation Context**:\n\n1.  **Who is the source of the data?**\n    *   If the context implies the **authors themselves** are the source (e.g., \"we,\" \"our\"), classify as **A**.\n    *   If the context names an **external source** (e.g., a repository, another study, a database), classify as **B**.\n\n2.  **What is the action being described?**\n    *   **A (Primary)** actions: *depositing, making available, presenting* their own data.\n    *   **B (Secondary)** actions: *using, obtaining, accessing, downloading, analyzing* existing data from elsewhere.\n\n## Examples for Pattern Recognition\n\n**Example 1 (Classify as B):**\n*   Context: \"Three out of four cohorts **used in this study** can be found on The Cancer Imaging Archive (TCIA)24: Canadian benchmark dataset23: https://doi.org/10.7937/K9/TCIA.2017.8oje5q00.\"\n*   **Reasoning:** The authors are describing external datasets they **used** (a Secondary action). The source is TCIA, not themselves.\n*   **Output:** B\n\n**Example 2 (Classify as A):**\n*   Context: \"Additional research data **supporting this publication are available** at 10.25377/sussex.21184705.\"\n*   **Reasoning:** The authors are stating the availability of data that **supports their own publication**. The source is implied to be themselves.\n*   **Output:** A\n\n**Example 3 (Classify as B):**\n*   Context: \"GBIF occurrence data: Vulpes vulpes: https://doi.org/10.15468/dl.wgtneb (28 May 2021).\"\n*   **Reasoning:** The data is explicitly sourced from an external repository (GBIF). The authors are referring to data they reused.\n*   **Output:** B\n\n**Example 4 (Classify as A):**\n*   Context: \"Data referring to Barbieux et al. (2017; https://doi.org/10.17882/49388) are freely available on SEANOE.\"\n*   **Reasoning:** This is a tricky case. The citation format \"(Author et al. Year)\" suggests a literature reference. However, the phrase \"Data referring to\" and the direct data DOI indicate the authors are citing **their own previously published dataset** (from a 2017 paper) that is now available. This is their Primary data.\n*   **Output:** A\n\n## Ready for Input\nBegin your analysis. Remember: Output only **A** or **B**.\n\n'''\n\ndef get_context_window(text: str, substring: str, window: int = 600) -> str:\n    idx = text.find(substring)\n    if idx == -1:\n        return \"no context\", \"no abstraction\"\n    start = max(idx - window, 0)\n    end = min(idx + len(substring) + window, len(text))\n    return text[start:end] , text[:1000]\n\n\n\n\ndef find_context_win(tokenizer,df):\n    text_df = pl.read_parquet('/tmp/context_data.parquet')\n    # print(text_df)\n    df = df.join(text_df, on=[\"article_id\",\"dataset_id\"], how=\"inner\")\n    df = df.drop(\"type\")\n    print(df)\n\n    prompts = []\n    \n    for article_id,dataset_id,text,match in df.select([\"article_id\",\"dataset_id\",\"text\",'match']).rows():\n\n        context, abstract = get_context_window(text,match)\n        user_content = f\"\"\"\n        Paper Abstract: {abstract}\n        \n        Citation: {dataset_id}\n\n        \n        Citation Context: {context}\n        \"\"\"\n        messages = [\n            {\"role\": \"system\", \"content\": PROMPT_CLASSIFY_CITATION_TYPE},\n            {\"role\": \"user\", \"content\": user_content.strip()}\n        ]\n        prompts.append(\n            tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n        )\n        \n    return df.with_columns(pl.Series(\"prompt\", prompts))\n\n    \n\nif __name__==\"__main__\":\n    os.environ[\"VLLM_USE_V1\"] = \"0\"\n    MODEL_PATH = \"/kaggle/input/qwen2.5/transformers/32b-instruct-awq/1\"\n    import vllm\n    from logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\n\n    llm = vllm.LLM(\n        MODEL_PATH,\n        quantization='awq',\n        tensor_parallel_size=2,\n        gpu_memory_utilization=0.9,\n        trust_remote_code=True,\n        dtype=\"half\",\n        enforce_eager=True,\n        max_model_len=16384,\n        disable_log_stats=True, \n        disable_custom_all_reduce=True,\n        enable_prefix_caching=True,\n        task='generate')\n\n    tokenizer = llm.get_tokenizer()\n\n    df=pl.read_csv(\"/kaggle/working/submission.csv\")\n    \n    if \"row_id\" in df.columns:\n        df = df.drop(\"row_id\")\n\n\n    doi_df = df.filter(is_doi_link(\"dataset_id\"))\n    acc_df = df.filter(~is_doi_link(\"dataset_id\"))\n\n\n\n    df = find_context_win(tokenizer,doi_df)\n\n    \n    \n    prompts = df['prompt'].to_list()\n    mclp = MultipleChoiceLogitsProcessor(tokenizer, choices=[\"A\", \"B\"])\n    outputs = llm.generate(prompts, vllm.SamplingParams(seed=777, temperature=0.8, skip_special_tokens=True, max_tokens=1, logits_processors=[mclp], logprobs=len(mclp.choices)), use_tqdm=True)\n    logprobs = [{lp.decoded_token: lp.logprob for lp in list(lps)} for lps in [output.outputs[0].logprobs[0].values() for output in outputs]]\n    choices = [max(d, key=d.get) for d in logprobs]\n    types = {'A':'Primary', 'B':'Secondary'}\n    choices = [types[c] for c in choices]\n\n\n    \n    df = df.with_columns(pl.Series('type', choices))\n    df.select('article_id', 'dataset_id','type').write_csv('/tmp/doi_sub.csv')\n\n    acc_df = assume_type(acc_df)\n    acc_df.select('article_id','dataset_id','type').write_csv(\"/tmp/accid_sub.csv\")\n    df = pl.concat([pl.read_csv('/tmp/doi_sub.csv'), pl.read_csv('/tmp/accid_sub.csv')])\n    \n    df.select(['article_id', 'dataset_id', 'type']).with_row_index(name='row_id').write_csv('/kaggle/working/submission.csv')\n    # print(df)\n    if not IS_KAGGLE_SUBMISSION:\n        results = evaluate(df)\n        for r in results: l.info(r) \n        results = evaluate(df, on=['article_id', 'dataset_id', 'type'])\n        for r in results: l.info(r)\n    \n    \n    try:\n        del llm, tokenizer\n    except:\n        pass\n    \n    import gc, torch\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /tmp\n!LOG_LEVEL=INFO python src/parse.py /tmp/train_parse\n! python src/check_parse.py\n! python src/getid.py\n! python src/llm_validate.py\n! python src/post_filter.py\n! python src/post_validate.py\n! python src/predict.py\n! grep \"f1:\" /tmp/logs/project.log","metadata":{"_cell_guid":"c6a12705-737a-4b21-9bf2-125b3d1ab724","_kg_hide-output":true,"_uuid":"bc8e0d68-3097-4ce9-99a1-536921913550","collapsed":false,"execution":{"iopub.status.busy":"2025-08-01T03:49:31.098697Z","iopub.execute_input":"2025-08-01T03:49:31.098966Z","execution_failed":"2025-08-01T03:54:18.903Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":448.641642,"end_time":"2025-07-30T12:51:19.65281","exception":false,"start_time":"2025-07-30T12:43:51.011168","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.009673,"end_time":"2025-07-30T12:51:19.672901","exception":false,"start_time":"2025-07-30T12:51:19.663228","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}